ğŸ¤– REPORTE DE INVESTIGACIÃ“N: LLM AGENTS
=======================================

ğŸ“„ TÃTULO: Policy Compiler for Secure Agentic Systems
ğŸ”— LINK: http://arxiv.org/abs/2602.16708v1
ğŸ“ RESUMEN: LLM-based agents are increasingly being deployed in contexts requiring complex authorization policies: customer service protocols, approval workflows, data access restrictions, and regulatory compliance. Embedding these policies in prompts provides no enforcement guarantees. We present PCAS, a Polic...
----------------------------------------

ğŸ“„ TÃTULO: Measuring Mid-2025 LLM-Assistance on Novice Performance in Biology
ğŸ”— LINK: http://arxiv.org/abs/2602.16703v1
ğŸ“ RESUMEN: Large language models (LLMs) perform strongly on biological benchmarks, raising concerns that they may help novice actors acquire dual-use laboratory skills. Yet, whether this translates to improved human performance in the physical laboratory remains unclear. To address this, we conducted a pre-reg...
----------------------------------------

ğŸ“„ TÃTULO: Saliency-Aware Multi-Route Thinking: Revisiting Vision-Language Reasoning
ğŸ”— LINK: http://arxiv.org/abs/2602.16702v1
ğŸ“ RESUMEN: Vision-language models (VLMs) aim to reason by jointly leveraging visual and textual modalities. While allocating additional inference-time computation has proven effective for large language models (LLMs), achieving similar scaling in VLMs remains challenging. A key obstacle is that visual inputs a...
----------------------------------------

ğŸ“„ TÃTULO: Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents
ğŸ”— LINK: http://arxiv.org/abs/2602.16699v1
ğŸ“ RESUMEN: LLMs are increasingly being used for complex problems which are not necessarily resolved in a single response, but require interacting with an environment to acquire information. In these scenarios, LLMs must reason about inherent cost-uncertainty tradeoffs in when to stop exploring and commit to an...
----------------------------------------

ğŸ“„ TÃTULO: Causality is Key for Interpretability Claims to Generalise
ğŸ”— LINK: http://arxiv.org/abs/2602.16698v1
ğŸ“ RESUMEN: Interpretability research on large language models (LLMs) has yielded important insights into model behaviour, yet recurring pitfalls persist: findings that do not generalise, and causal interpretations that outrun the evidence. Our position is that causal inference specifies what constitutes a vali...
----------------------------------------

